{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "METHOD\n",
    "\n",
    "1) Train a model fully with the leNet5 net and the mnist dataset\n",
    "2) Retrive it's weights (for each parameters and compute it's loss function)\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the LeNet5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Loss: 0.1958, Accuracy: 93.77%\n",
      "Epoch: 2/5, Loss: 0.0628, Accuracy: 98.08%\n",
      "Epoch: 3/5, Loss: 0.0471, Accuracy: 98.61%\n",
      "Epoch: 4/5, Loss: 0.0371, Accuracy: 98.82%\n",
      "Epoch: 5/5, Loss: 0.0301, Accuracy: 99.07%\n"
     ]
    }
   ],
   "source": [
    "# Training of the model\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "# Train the model and store the loss values\n",
    "model = LeNet5()\n",
    "# parameters \n",
    "num_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_values.append(loss.item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    avg_loss = total_loss / (i + 1)\n",
    "    print(f'Epoch: {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')  \n",
    "\n",
    "# Save the trained model weights\n",
    "model_weights_path = 'models_weights/lenet5_mnist_weights.pth'\n",
    "torch.save(model.state_dict(), model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF THE MODEL IS ALREADY TRAINED\n",
    "# Load the saved model\n",
    "model_weights_path = 'models_weights/lenet5_mnist_weights.pth'\n",
    "saved_weights = torch.load(model_weights_path)\n",
    "# Create a new model and load the saved weights\n",
    "learnt_net = LeNet5()\n",
    "learnt_net.load_state_dict(saved_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways of plotting th loss function \n",
    "Neural networks are trained on a corpus of feature vectors (e.g., images) {xi} and accompanying\n",
    "labels {yi} by minimizing a loss of the form L(θ) = sum (for i in dataset) Loss (xi, yi; θ), where θ denotes the\n",
    "parameters (weights) of the neural network, the function `(xi, yi; θ) measures how well the neural\n",
    "network with parameters θ predicts the label of a data sample, and m is the number of data samples.\n",
    "Neural nets contain many parameters, and so their loss functions live in a very high-dimensional\n",
    "space. Unfortunately, visualizations are only possible using low-dimensional 1D (line) or 2D (surface)\n",
    "plots. Several methods exist for closing this dimensionality gap.\n",
    "1-Dimensional Linear Interpolation One simple and lightweight way to plot loss functions is\n",
    "to choose two sets of parameters θ and θ\n",
    "0\n",
    ", and plot the values of the loss function along the line\n",
    "connecting these two points. We can parameterize this line by choosing a scalar parameter α, and\n",
    "defining the weighted average θ(α) = (1−α)θ+αθ0\n",
    ". Finally, we plot the function f(α) = L(θ(α)).\n",
    "This strategy was taken by Goodfellow et al. [13], who studied the loss surface along the line between\n",
    "a random initial guess, and a nearby minimizer obtained by stochastic gradient descent. This method\n",
    "has been widely used to study the “sharpness” and “flatness” of different minima, and the dependence. However there is some limitation in the plotting of such a 1D loss landscape.\n",
    "\n",
    "For 2D visulization : \n",
    "Contour Plots & Random Directions To use this approach, one chooses a center point θ in the graph, and chooses two direction vectors, δ and η. One then plots a function of the form\n",
    "f(α) = L(θ + αδ) in the 1D (line) case, or f(α, β) = L(θ∗ + αδ + βη)\n",
    "\n",
    "# Interesting approch : Filter-Wise Normalization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import (\n",
    "  parameters_to_vector as Params2Vec,\n",
    "  vector_to_parameters as Vec2Params\n",
    ")\n",
    "\n",
    "theta_ast = Params2Vec(learnt_net.parameters())\n",
    "\n",
    "infer_net = LeNet5()\n",
    "theta = Params2Vec(infer_net.parameters())\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_ast.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to plot the loss fucntion from internet\n",
    "\n",
    "\"\"\"\n",
    "x = torch.linspace(-20, 20, 20)\n",
    "y = torch.linspace(-20, 20, 20)\n",
    "alpha, beta = torch.meshgrid(x, y)\n",
    "space = tau_2d(alpha, beta, theta_ast)\n",
    "\n",
    "losses = torch.empty_like(space[0, :, :])\n",
    "\n",
    "for a, _ in enumerate(x):\n",
    "  print(f'a = {a}')\n",
    "  for b, _ in enumerate(y):\n",
    "    Vec2Params(space[:, a, b], infer_net.parameters())\n",
    "    for _, (data, label) in enumerate(train_loader):\n",
    "      with torch.no_grad():\n",
    "        infer_net.eval()\n",
    "        losses[a][b] = loss_fn(infer_net(data), label).item()\n",
    "        \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "def tau_2d(alpha, beta, theta_ast):\n",
    "  a = alpha * theta_ast[:,None,None]\n",
    "  b = beta * alpha * theta_ast[:,None,None]\n",
    "  return a + b\n",
    "\n",
    "# Define the range and step size\n",
    "x = torch.linspace(-100, 100, 10)\n",
    "y = torch.linspace(-100, 100, 10) \n",
    "\n",
    "alpha, beta = torch.meshgrid(x, y)\n",
    "space = tau_2d(alpha, beta, theta_ast)\n",
    "\n",
    "losses = torch.empty_like(space[0, :, :])\n",
    "\n",
    "# Set batch size and create data loader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Making the loss landscape on only one batch\n",
    "\n",
    "data, label = next(iter(train_loader))\n",
    "\n",
    "# Maybe try to see it on one batch only\n",
    "for a, _ in enumerate(x):\n",
    "    #print(f'a = {a}')\n",
    "    for b, _ in enumerate(y):\n",
    "        Vec2Params(space[:, a, b], infer_net.parameters())\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            infer_net.eval()\n",
    "            batch_size = data.size(0)\n",
    "            total_samples += batch_size\n",
    "            loss = loss_fn(infer_net(data), label)\n",
    "            total_loss += loss.item() * batch_size\n",
    "\n",
    "        losses[a][b] = total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the table to a file\n",
    "np.savetxt('loss_landscape.txt', losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the table from the file\n",
    "loadedTable = np.loadtxt('loss_landscape.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.95615836e+20, -2.79314533e+20, -5.05953646e+19,\n",
       "        -3.69971507e+18, -1.10639614e+16, -6.70278910e+16,\n",
       "        -1.22719659e+19, -1.48836843e+20, -7.80463471e+20,\n",
       "        -2.70358995e+21],\n",
       "       [-2.83380158e+20, -7.95007336e+19, -1.44008601e+19,\n",
       "        -1.05304256e+18, -3.14911324e+15, -1.90780300e+16,\n",
       "        -3.49294668e+18, -4.23631451e+19, -2.22141811e+20,\n",
       "        -7.69517402e+20],\n",
       "       [-5.26901321e+19, -1.47819256e+19, -2.67761565e+18,\n",
       "        -1.95796890e+17, -5.85528462e+14, -3.54726852e+15,\n",
       "        -6.49459391e+17, -7.87676991e+18, -4.13038272e+19,\n",
       "        -1.43079835e+20],\n",
       "       [-4.09718495e+18, -1.14944265e+18, -2.08211407e+17,\n",
       "        -1.52251662e+16, -4.55306505e+13, -2.75836456e+14,\n",
       "        -5.05020422e+16, -6.12498277e+17, -3.21178726e+18,\n",
       "        -1.11258955e+19],\n",
       "       [-1.68608551e+16, -4.73021928e+15, -8.56837520e+14,\n",
       "        -6.26549745e+13, -1.87368260e+11, -1.13514853e+12,\n",
       "        -2.07828720e+14, -2.52058048e+15, -1.32172830e+16,\n",
       "        -4.57857258e+16],\n",
       "       [-4.14285029e+16, -1.16225466e+16, -2.10532559e+15,\n",
       "        -1.53949496e+14, -4.60393611e+11, -4.61978698e+11,\n",
       "        -8.45829972e+13, -1.02584072e+15, -5.37925649e+15,\n",
       "        -1.86341902e+16],\n",
       "       [-1.00670900e+19, -2.82426769e+18, -5.11591559e+17,\n",
       "        -3.74094830e+16, -1.11873429e+14, -1.12261125e+14,\n",
       "        -2.05536777e+16, -2.49279180e+17, -1.30715866e+18,\n",
       "        -4.52810444e+18],\n",
       "       [-1.29463571e+20, -3.63202995e+19, -6.57910485e+18,\n",
       "        -4.81088186e+17, -1.43869593e+15, -1.44368843e+15,\n",
       "        -2.64321960e+17, -3.20575067e+18, -1.68101639e+19,\n",
       "        -5.82317983e+19],\n",
       "       [-6.96285846e+20, -1.95339201e+20, -3.53839840e+19,\n",
       "        -2.58740567e+18, -7.73763752e+15, -7.76450415e+15,\n",
       "        -1.42158676e+18, -1.72412934e+19, -9.04090852e+19,\n",
       "        -3.13184575e+20],\n",
       "       [-2.44630127e+21, -6.86296299e+20, -1.24316581e+20,\n",
       "        -9.09047682e+18, -2.71850621e+16, -2.72794826e+16,\n",
       "        -4.99454311e+18, -6.05748268e+19, -3.17639445e+20,\n",
       "        -1.10032938e+21]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# without normalization\n",
    "type(loadedTable)\n",
    "def plot_2d_array(array):\n",
    "    plt.imshow(array, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "plot_2d_array(loadedTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "def filterwise_normalize(direction, model):\n",
    "    norm_direction = []\n",
    "    idx = 0\n",
    "    for param in model.parameters():\n",
    "        param_size = param.size()\n",
    "        param_direction = direction[idx: idx + param.numel()].view(param_size)\n",
    "        norm_param_direction = param_direction * (param.norm() / param_direction.norm())\n",
    "        norm_direction.append(norm_param_direction)\n",
    "        idx += param.numel()\n",
    "    return norm_direction\n",
    "\n",
    "def loss_landscape(model, criterion, data, labels, center, alpha_range, beta_range, num_steps):\n",
    "    model.eval()\n",
    "    grid_loss = np.zeros((num_steps, num_steps))\n",
    "    random_direction1 = torch.normal(mean=0, std=1, size=(sum(p.numel() for p in model.parameters()),))\n",
    "    random_direction2 = torch.normal(mean=0, std=1, size=(sum(p.numel() for p in model.parameters()),))\n",
    "    \n",
    "    direction1 = filterwise_normalize(random_direction1, model)\n",
    "    direction2 = filterwise_normalize(random_direction2, model)\n",
    "    \n",
    "    original_params = [param.clone() for param in model.parameters()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(alpha_range):\n",
    "            for j, beta in enumerate(beta_range):\n",
    "                for original_param, param, d1, d2 in zip(original_params, model.parameters(), direction1, direction2):\n",
    "                    param_size = param.size()\n",
    "                    update = (alpha * d1.view(-1) + beta * d2.view(-1)).view(param_size)\n",
    "                    param.data.copy_(original_param + update)\n",
    "                \n",
    "                temp_output = model(data)\n",
    "                grid_loss[j, i] = criterion(temp_output, labels).item()\n",
    "    \n",
    "    # Restore the original parameters\n",
    "    for original_param, param in zip(original_params, model.parameters()):\n",
    "        param.data.copy_(original_param)\n",
    "    \n",
    "    return grid_loss\n",
    "\n",
    "# Generate a random mini-batch from the train_loader\n",
    "data, labels = next(iter(train_loader))\n",
    "\n",
    "# Generate the alpha and beta range for the plot\n",
    "num_steps = 10\n",
    "alpha_range = np.linspace(-1, 1, num_steps)\n",
    "beta_range = np.linspace(-1, 1, num_steps)\n",
    "\n",
    "# Compute the loss landscape\n",
    "grid_loss = loss_landscape(model, criterion, data, labels, model.state_dict(), alpha_range, beta_range, num_steps)\n",
    "\n",
    "# Plot the loss landscape\n",
    "plt.contourf(alpha_range, beta_range, grid_loss, levels=100, cmap=\"viridis\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Beta\")\n",
    "plt.title(\"Loss Landscape with Filter-wise Normalization\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
